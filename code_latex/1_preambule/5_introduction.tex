\chapter*{Introduction}

% Ajouter manuellement cette section à la table des matières
\addcontentsline{toc}{chapter}{Introduction}

Dans un contexte réglementaire exigeant et en constante évolution, les organismes d’assurance sont amenés à renforcer la robustesse, la traçabilité et la transparence de leurs méthodes de valorisation des engagements. Depuis l’entrée en vigueur de la directive Solvabilité II, le calcul des provisions techniques repose sur une approche économique cohérente avec les conditions de marché, dont le Best Estimate (BE) constitue un élément central. Il représente l’espérance actualisée des flux futurs liés aux engagements d’assurance et joue un rôle déterminant dans l’évaluation de la situation financière des assureurs.

Dans le cadre de Solvabilité II, le Best Estimate stochastique est considéré comme une référence pour la valorisation des engagements, dans la mesure où il permet d’intégrer l’incertitude liée aux évolutions futures des variables économiques et financières. Néanmoins, en pratique, les assureurs ont également recours à des approches déterministes, notamment pour des besoins d’analyse, de comparaison ou de compréhension des résultats. Le passage du BE déterministe au BE stochastique soulève alors des enjeux importants de traçabilité, de justification et de maîtrise des écarts, en particulier dans un contexte où les résultats produits par les modèles doivent être compris, expliqués et documentés.

Ainsi, le passage du BE déterministe au BE stochastique constitue un enjeu à la fois technique, opérationnel et réglementaire. S’il est admis que le BE stochastique offre une vision plus complète du risque, la compréhension des facteurs expliquant les différences entre ces deux approches reste un sujet clé, notamment en termes de gouvernance des modèles, de transparence vis-à-vis des parties prenantes et de maîtrise des résultats.

Dans ce contexte, les avancées récentes en machine learning ouvrent de nouvelles perspectives. Ces méthodes permettent d’exploiter des bases de données complexes afin de modéliser des relations non linéaires entre variables explicatives et variables cibles, tout en offrant des outils d’analyse de l’importance des facteurs explicatifs. Appliquées au cadre actuariel, elles peuvent constituer un outil complémentaire aux modèles traditionnels, non pas dans une logique de substitution, mais dans une démarche de compréhension et de rationalisation des résultats.

Ce mémoire s’inscrit dans cette dynamique et a pour objectif de rationnaliser le passage du BE stochastique au BE déterministe à l’aide de modèles de machine learning, en mettant l’accent sur la transparence et l’interprétabilité des résultats. Plus précisément, il vise à identifier et analyser les variables expliquant les écarts entre ces deux approches, en s’appuyant sur des données issues d’un modèle ALM interne utilisé en cabinet de conseil. Le BE stochastique constitue la variable cible des modèles, tandis que le BE déterministe et d’autres variables majoritairement liées au passif sont intégrées comme variables explicatives.


Ce mémoire s’articule autour des parties suivantes :

La première partie rappelle les fondements réglementaires de Solvabilité II relatifs au calcul du Best Estimate, en présentant les principes du BE déterministe et du BE stochastique ainsi que leurs rôles respectifs dans le cadre prudentiel.

La deuxième partie décrit le modèle ALM interne utilisé pour cette étude et la méthodologie de construction de la base de données. Elle précise les hypothèses retenues, les variables explicatives considérées, principalement au passif, ainsi que les choix de paramétrage effectués.

La troisième partie présente les principes théoriques des modèles de machine learning utilisés pour les problèmes de régression, les critères de performance retenus, ainsi que les enjeux d’interprétabilité et d’explicabilité, essentiels dans un cadre actuariel et réglementaire.

La quatrième partie est consacrée à l’analyse des résultats obtenus. Elle met en évidence les variables les plus explicatives du BE stochastique, propose une lecture actuarielle des écarts observés entre BE déterministe et BE stochastique, et en dégage les grandes tendances.

Enfin, la dernière partie discute les limites de l’approche proposée ainsi que les perspectives d’amélioration et d’extension du cadre d’analyse.

Ainsi, ce mémoire se situe à l’interface entre les exigences prudentielles, les contraintes opérationnelles des modèles ALM et les nouvelles méthodes d’analyse issues du machine learning. Il s’inscrit dans une démarche visant à renforcer la transparence, la compréhension et la maîtrise du calcul du Best Estimate en assurance vie.